{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn\n",
    "\n",
    "## Basic preprocessing and model fitting\n",
    "\n",
    "In this notebook, we present how to build predictive models on tabular\n",
    "datasets.\n",
    "\n",
    "In particular we will highlight:\n",
    "* the difference between numerical and categorical variables;\n",
    "* the importance of scaling numerical variables;\n",
    "* typical ways to deal categorical variables;\n",
    "* train predictive models on different kinds of data;\n",
    "* evaluate the performance of a model via cross-validation.\n",
    "\n",
    "## Introducing the dataset\n",
    "\n",
    "To this aim, we will use data from the 1994 Census bureau database. The goal\n",
    "with this data is to regress wages from heterogeneous data such as age,\n",
    "employment, education, family information, etc.\n",
    "\n",
    "Let's first load the data located in the `datasets` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://www.openml.org/data/get_csv/1595261/adult-census.csv\")\n",
    "\n",
    "# Or use the local copy:\n",
    "# df = pd.read_csv('../datasets/adult-census.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first records of this data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
       "0   25     Private  226802           11th              7        Never-married   \n",
       "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?  103497   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   class  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              50   United-States   <=50K  \n",
       "2             0              40   United-States    >50K  \n",
       "3             0              40   United-States    >50K  \n",
       "4             0              30   United-States   <=50K  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable in our study will be the \"class\" column while we will use\n",
    "the other columns as input variables for our model. This target column divides\n",
    "the samples (also known as records) into two groups: high income (>50K) vs low\n",
    "income (<=50K). The resulting prediction problem is therefore a binary\n",
    "classification problem.\n",
    "\n",
    "For simplicity, we will ignore the \"fnlwgt\" (final weight) column that was\n",
    "crafted by the creators of the dataset when sampling the dataset to be\n",
    "representative of the full census database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name].to_numpy()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education  education-num       marital-status  \\\n",
       "0   25     Private           11th              7        Never-married   \n",
       "1   38     Private        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country  \n",
       "0             0              40   United-States  \n",
       "1             0              50   United-States  \n",
       "2             0              40   United-States  \n",
       "3             0              40   United-States  \n",
       "4             0              30   United-States  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=[target_name, \"fnlwgt\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of samples and the number of features available in\n",
    "the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 48842 samples and 13 features\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The dataset contains {data.shape[0]} samples and {data.shape[1]} \"\n",
    "    \"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with numerical data\n",
    "\n",
    "The numerical data is the most natural type of data used in machine learning\n",
    "and can (almost) directly be fed to predictive models. We can quickly have a\n",
    "look at such data by selecting the subset of columns from the original data.\n",
    "\n",
    "We will use this subset of data to fit a linear classification model to\n",
    "predict the income class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education-num', 'marital-status',\n",
       "       'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
       "       'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int64 means it's coded in 64 bits - means the max number you can get is 2**64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = [c for c in data.columns\n",
    "                     if data[c].dtype.kind in [\"i\", \"f\"]]\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education-num  capital-gain  capital-loss  hours-per-week\n",
       "0   25              7             0             0              40\n",
       "1   38              9             0             0              50\n",
       "2   28             12             0             0              40\n",
       "3   44             10          7688             0              40\n",
       "4   18             10             0             0              30"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numeric = data[numerical_columns]\n",
    "data_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a machine learning model, it is important to leave out a\n",
    "subset of the data which we can use later to evaluate the trained model.\n",
    "The data used to fit a model a called training data while the one used to\n",
    "assess a model are called testing data.\n",
    "\n",
    "Scikit-learn provides an helper function `train_test_split` which will\n",
    "split the dataset into a training and a testing set. It will ensure that\n",
    "the data are shuffled randomly before splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset contains 36631 samples and 5 features\n",
      "The testing dataset contains 12211 samples and 5 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_numeric, target, random_state=42\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The training dataset contains {data_train.shape[0]} samples and \"\n",
    "    f\"{data_train.shape[1]} features\"\n",
    ")\n",
    "print(\n",
    "    f\"The testing dataset contains {data_test.shape[0]} samples and \"\n",
    "    f\"{data_test.shape[1]} features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We will build a linear classification model called \"Logistic Regression\". The\n",
    "`fit` method is called to train the model from the input and target data. Only\n",
    "the training data should be given for this purpose.\n",
    "\n",
    "In addition, when checking the time required to train the model and internally\n",
    "check the number of iterations done by the solver to find a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that LogisticRegression is a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbfgs is a powerful algorithm for smooth optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model LogisticRegression was trained in 0.535 seconds for [105] iterations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "\n",
    "print(\n",
    "    f\"The model {model.__class__.__name__} was trained in \"\n",
    "    f\"{elapsed_time:.3f} seconds for {model.n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ignore the convergence warning for now and instead let's try\n",
    "to use our model to make some predictions on the first three records\n",
    "of the held out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_predicted = model.predict(data_test)\n",
    "target_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>predicted-class</th>\n",
       "      <th>expected-class</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23881</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30507</th>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>14344</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28911</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19484</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "7762    56              9             0             0              40   \n",
       "23881   25              9             0             0              40   \n",
       "30507   43             13         14344             0              40   \n",
       "28911   32              9             0             0              40   \n",
       "19484   39             13             0             0              30   \n",
       "\n",
       "      predicted-class expected-class  correct  \n",
       "7762            <=50K          <=50K     True  \n",
       "23881           <=50K          <=50K     True  \n",
       "30507            >50K           >50K     True  \n",
       "28911           <=50K          <=50K     True  \n",
       "19484           <=50K          <=50K     True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = data_test.copy()\n",
    "predictions['predicted-class'] = target_predicted\n",
    "predictions['expected-class'] = target_test\n",
    "predictions['correct'] = target_predicted == target_test\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantitatively evaluate our model, we can use the method `score`. It will\n",
    "compute the classification accuracy when dealing with a classificiation\n",
    "problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy using a LogisticRegression is 0.818\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The test accuracy using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mathematically equivalent as computing the average number of time\n",
    "the model makes a correct prediction on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177872410122021"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_test == target_predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- What would be the score of a model that always predicts `' >50K'`?\n",
    "- What would be the score of a model that always predicts `' <= 50K'`?\n",
    "- Is 81% or 82% accuracy a good score for this problem?\n",
    "\n",
    "Hint: You can compute the cross-validated of a [DummyClassifier](https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators) the performance of such baselines.\n",
    "\n",
    "Use the dedicated notebook to do this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177872410122021"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_test == target_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf.fit(data_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K'], dtype='<U6')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clf.predict(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7660306281221849"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(data_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider the `ConvergenceWarning` message that was raised previously\n",
    "when calling the `fit` method to train our model. This warning informs us that\n",
    "our model stopped learning becaused it reached the maximum number of\n",
    "iterations allowed by the user. This could potentially be detrimental for the\n",
    "model accuracy. We can follow the (bad) advice given in the warning message\n",
    "and increase the maximum number of iterations allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using a LogisticRegression is 0.818 with a fitting time of 0.541 seconds in [105] iterations\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The accuracy using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.3f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds in {model.n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT'S ONLY ONCE YOU HAVE FIT THAT YOU HAVE THE VARIABLES THAT END IN _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe now a longer training time but not significant improvement in\n",
    "the predictive performance. Instead of increasing the number of iterations, we\n",
    "can try to help fit the model faster by scaling the data first. A range of\n",
    "preprocessing algorithms in scikit-learn allows to transform the input data\n",
    "before training a model. We can easily combine these sequential operation with\n",
    "a scikit-learn `Pipeline` which will chain the operations and can be used as\n",
    "any other classifier or regressor. The helper function `make_pipeline` will\n",
    "create a `Pipeline` by giving the successive transformations to perform.\n",
    "\n",
    "In our case, we will standardize the data and then train a new logistic\n",
    "regression model on that new version of the dataset set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36631.000000</td>\n",
       "      <td>36631.000000</td>\n",
       "      <td>36631.000000</td>\n",
       "      <td>36631.000000</td>\n",
       "      <td>36631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.642352</td>\n",
       "      <td>10.078131</td>\n",
       "      <td>1087.077721</td>\n",
       "      <td>89.665311</td>\n",
       "      <td>40.431247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.725748</td>\n",
       "      <td>2.570143</td>\n",
       "      <td>7522.692939</td>\n",
       "      <td>407.110175</td>\n",
       "      <td>12.423952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education-num  capital-gain  capital-loss  hours-per-week\n",
       "count  36631.000000   36631.000000  36631.000000  36631.000000    36631.000000\n",
       "mean      38.642352      10.078131   1087.077721     89.665311       40.431247\n",
       "std       13.725748       2.570143   7522.692939    407.110175       12.423952\n",
       "min       17.000000       1.000000      0.000000      0.000000        1.000000\n",
       "25%       28.000000       9.000000      0.000000      0.000000       40.000000\n",
       "50%       37.000000      10.000000      0.000000      0.000000       40.000000\n",
       "75%       48.000000      12.000000      0.000000      0.000000       45.000000\n",
       "max       90.000000      16.000000  99999.000000   4356.000000       99.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17177061,  0.35868902, -0.14450843,  5.71188483, -2.28845333],\n",
       "       [ 0.02605707,  1.1368665 , -0.14450843, -0.22025127, -0.27618374],\n",
       "       [-0.33822677,  1.1368665 , -0.14450843, -0.22025127,  0.77019645],\n",
       "       ...,\n",
       "       [-0.77536738, -0.03039972, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 0.53605445,  0.35868902, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 1.48319243,  1.52595523, -0.14450843, -0.22025127, -2.69090725]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_train_scaled = scaler.fit_transform(data_train)\n",
    "data_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.663100e+04</td>\n",
       "      <td>3.663100e+04</td>\n",
       "      <td>3.663100e+04</td>\n",
       "      <td>3.663100e+04</td>\n",
       "      <td>3.663100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.263553e-16</td>\n",
       "      <td>-1.465224e-16</td>\n",
       "      <td>-1.708425e-15</td>\n",
       "      <td>-1.652358e-15</td>\n",
       "      <td>1.146502e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000014e+00</td>\n",
       "      <td>1.000014e+00</td>\n",
       "      <td>1.000014e+00</td>\n",
       "      <td>1.000014e+00</td>\n",
       "      <td>1.000014e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.576792e+00</td>\n",
       "      <td>-3.532198e+00</td>\n",
       "      <td>-1.445084e-01</td>\n",
       "      <td>-2.202513e-01</td>\n",
       "      <td>-3.173852e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.753674e-01</td>\n",
       "      <td>-4.194885e-01</td>\n",
       "      <td>-1.445084e-01</td>\n",
       "      <td>-2.202513e-01</td>\n",
       "      <td>-3.471139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.196565e-01</td>\n",
       "      <td>-3.039972e-02</td>\n",
       "      <td>-1.445084e-01</td>\n",
       "      <td>-2.202513e-01</td>\n",
       "      <td>-3.471139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.817680e-01</td>\n",
       "      <td>7.477778e-01</td>\n",
       "      <td>-1.445084e-01</td>\n",
       "      <td>-2.202513e-01</td>\n",
       "      <td>3.677425e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.741752e+00</td>\n",
       "      <td>2.304133e+00</td>\n",
       "      <td>1.314865e+01</td>\n",
       "      <td>1.047970e+01</td>\n",
       "      <td>4.714245e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education-num  capital-gain  capital-loss  hours-per-week\n",
       "count  3.663100e+04   3.663100e+04  3.663100e+04  3.663100e+04    3.663100e+04\n",
       "mean  -1.263553e-16  -1.465224e-16 -1.708425e-15 -1.652358e-15    1.146502e-16\n",
       "std    1.000014e+00   1.000014e+00  1.000014e+00  1.000014e+00    1.000014e+00\n",
       "min   -1.576792e+00  -3.532198e+00 -1.445084e-01 -2.202513e-01   -3.173852e+00\n",
       "25%   -7.753674e-01  -4.194885e-01 -1.445084e-01 -2.202513e-01   -3.471139e-02\n",
       "50%   -1.196565e-01  -3.039972e-02 -1.445084e-01 -2.202513e-01   -3.471139e-02\n",
       "75%    6.817680e-01   7.477778e-01 -1.445084e-01 -2.202513e-01    3.677425e-01\n",
       "max    3.741752e+00   2.304133e+00  1.314865e+01  1.047970e+01    4.714245e+00"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_scaled = pd.DataFrame(data_train_scaled, columns=data_train.columns)\n",
    "data_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs'))\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using a Pipeline is 0.818 with a fitting time of 0.164 seconds in [13] iterations\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The accuracy using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.3f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds in {model[-1].n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We can see that the training time and the number of iterations is much shorter\n",
    "while the predictive performance (accuracy) stays the same.\n",
    "\n",
    "In the previous example, we split the original data into a training set and a\n",
    "testing set. This strategy has several issues: in the setting where the amount\n",
    "of data is limited, the subset of data used to train or test will be small;\n",
    "and the splitting was done in a random manner and we have no information\n",
    "regarding the confidence of the results obtained.\n",
    "\n",
    "Instead, we can use what cross-validation. Cross-validation consists in\n",
    "repeating this random splitting into training and testing sets and aggregate\n",
    "the model performance. By repeating the experiment, one can get an estimate of\n",
    "the variabilty of the model performance.\n",
    "\n",
    "The function `cross_val_score` allows for such experimental protocol by giving\n",
    "the model, the data and the target. Since there exists several\n",
    "cross-validation strategies, `cross_val_score` takes a parameter `cv` which\n",
    "defines the splitting strategy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different scores obtained are: \n",
      "[0.81216092 0.8096018  0.81337019 0.81326781 0.82207207]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, data_numeric, target, cv=5)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.814 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by computing the standard-deviation of the cross-validation scores\n",
    "we can get an idea of the uncertainty of our estimation of the predictive\n",
    "performance of the model: in the above results, only the first 2 decimals seem\n",
    "to be trustworthy. Using a single train / test split would not allow us to\n",
    "know anything about the level of uncertainty of the accuracy of the model.\n",
    "\n",
    "Setting `cv=5` created 5 distinct splits to get 5 variations for the training\n",
    "and testing sets. Each training set is used to fit one model which is then\n",
    "scored on the matching test set. This strategy is called K-fold\n",
    "cross-validation where `K` corresponds to the number of splits.\n",
    "\n",
    "The following matplotlib code helps visualize how the datasets is partitionned\n",
    "between train and test samples at each iteration of the cross-validation\n",
    "procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def plot_cv_indices(cv, X, y, ax, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    splits = list(cv.split(X=X, y=y))\n",
    "    n_splits = len(splits)\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (train, test) in enumerate(splits):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.zeros(shape=X.shape[0], dtype=np.int32)\n",
    "        indices[train] = 1\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits))\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits + .2, -.2], xlim=[0, 100])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of ticklabels (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m cv \u001b[38;5;241m=\u001b[39m KFold(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mplot_cv_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36mplot_cv_indices\u001b[1;34m(cv, X, y, ax, lw)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Formatting\u001b[39;00m\n\u001b[0;32m     26\u001b[0m yticklabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_splits))\n\u001b[1;32m---> 27\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m       \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSample index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCV iteration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m       \u001b[49m\u001b[43mylim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(cv)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py:116\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Artist\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1164\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1066\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[0;32m   1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:75\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1798\u001b[0m, in \u001b[0;36mAxis._set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fontdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(fontdict)\n\u001b[1;32m-> 1798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ticklabels(labels, minor\u001b[38;5;241m=\u001b[39mminor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1720\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of ticklabels is often used as a way to\u001b[39;00m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 ticklabels\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1721\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1722\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1724\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of ticklabels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ticklabels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1725\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, ticklabels)}\n\u001b[0;32m   1726\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of ticklabels (5)."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAFpCAYAAAC4SK2+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS/UlEQVR4nO3df6zdd33f8dd7tllLKKKbbxuWOA6VorKmUsp2ZdXLVnnQbQysMolUdSWmrlNkJewHTJ1aaLRUnZQ/Jk1VEa53FaW0TGWgCtM0QjEraotI/yDFMckKBLQokCaDNpd0jfEUNXN57497tl2u7s098edcn3OvHw/pKt/zPV9/zxt9ZPvJ95zzdXV3AAC4PH9l3gMAAOxmYgoAYICYAgAYIKYAAAaIKQCAAWIKAGDAVDFVVa+pqo9W1Zeq6vGqOrrh+WNV9XxVPTr5uXtnxgUAWCz7pzzufUk+0d23VdUrkrxyk2Me6u7jsxsNAGDxbRtTVfXqJD+S5J8lSXe/mOTFnR0LAGB3mOZtvu9Lsprk16rqc1V1X1Vds8lxR6vqsao6W1U3z3ZMAIDFVNv9czJVtZzkM0lu7e6Hq+p9SS50979bd8yrk3yruy9W1VuSvK+7b9rkXCeTnEySa6655m+//vWvn+H/FACAnfHII498o7uXNntumpi6NslnuvvGyeO/l+Q93f3Wl/g1X02y3N3f2OqY5eXlPnfu3PbTAwDMWVU90t3Lmz237dt83f0nSZ6uqu+f7HpTki9ueIFrq6om20cm531uaGoAgF1g2m/z/askH5p8k+/JJD9dVXckSXevJLktyZ1VdSnJC0lO9HaXvAAA9oBt3+bbKd7mAwB2i6G3+QAA2JqYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAH7pzmoqr6a5JtJ/jLJpe5e3vD8sSS/neQrk10f6+5/P7MpAQAW1FQxNfH3u/sbL/H8Q919fHQgAIDdxNt8AAADpo2pTvI7VfVIVZ3c4pijVfVYVZ2tqps3O6CqTlbVuao6t7q6elkDAwAskmnf5ru1u79WVd+T5JNV9aXu/vS6588nOdzdF6vqLUnuT3LTxpN0971J7k2S5eXlHhsdAGD+proy1d1fm/z32SS/leTIhucvdPfFyfaDSQ5U1cEZzwoAsHC2jamquqaqvuv/bif5h0k+v+GYa6uqJttHJud9bvbjAgAslmne5vveJL81aaX9Sf5Ld3+iqu5Iku5eSXJbkjur6lKSF5Kc6G5v4wEAe962MdXdTya5ZZP9K+u2TyU5NdvRAAAWn1sjAAAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAM2D/vAXbC0+98+7xHAGCPuufwffMegZew8nPffcVf05UpAIABYgoAYICYAgAYIKYAAAaIKQCAAVPHVFXtq6rPVdXHN3nuWFU9X1WPTn7unu2YAACL6eXcGuFdSR5P8uotnn+ou4+PjwQAsHtMdWWqqq5P8tYkbq4BALDOtG/z/XKSn03yrZc45mhVPVZVZ6vq5uHJAAB2gW1jqqqOJ3m2ux95icPOJznc3bckeX+S+7c418mqOldV51ZXVy9nXgCAhTLNlalbk/xYVX01yUeSvLGqfmP9Ad19obsvTrYfTHKgqg5uPFF339vdy929vLS0ND49AMCcbRtT3f3e7r6+u29MciLJ73X3O9YfU1XXVlVNto9MzvvcDswLALBQLvsfOq6qO5Kku1eS3Jbkzqq6lOSFJCe6u2czIgDA4npZMdXdn0ryqcn2yrr9p5KcmuVgAAC7gTugAwAMEFMAAAPEFADAADEFADBATAEADLjsWyMsskOnz8x7BAD2qJXtD+Eq48oUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADNg/7wF2wtPvfPu8RwAYds/h++Y9Apu466nb5z0CL+HQ6TNX/DVdmQIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABmwbU1X1HVX1h1X1WFV9oap+cZNjjlXV81X16OTn7p0ZFwBgsUxzn6m/SPLG7r5YVQeS/EFVne3uz2w47qHuPj77EQEAFte2MdXdneTi5OGByU/v5FAAALvFVJ+Zqqp9VfVokmeTfLK7H97ksKOTtwLPVtXNW5znZFWdq6pzq6urlz81AMCCmCqmuvsvu/uHklyf5EhV/eCGQ84nOdzdtyR5f5L7tzjPvd293N3LS0tLlz81AMCCeFnf5uvuP0/yqSRv3rD/QndfnGw/mORAVR2c0YwAAAtrmm/zLVXVaybb35nkR5N8acMx11ZVTbaPTM773MynBQBYMNN8m++1ST5YVfuyFkm/2d0fr6o7kqS7V5LcluTOqrqU5IUkJyYfXAcA2NOm+Tbff0vyhk32r6zbPpXk1GxHAwBYfO6ADgAwQEwBAAwQUwAAA8QUAMCAab7Nt+scOn1m3iMADFvZ/hDmwt8xfDtXpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGLB/3gPshKff+fZ5jwC7yj2H75v3CGzirqdun/cIsOscOn3mir+mK1MAAAPEFADAADEFADBATAEADBBTAAADxBQAwIBtY6qqDlXV71fV41X1hap61ybHHKuq56vq0cnP3TszLgDAYpnmPlOXkvxMd5+vqu9K8khVfbK7v7jhuIe6+/jsRwQAWFzbXpnq7q939/nJ9jeTPJ7kup0eDABgN3hZn5mqqhuTvCHJw5s8fbSqHquqs1V18xa//mRVnauqc6urqy9/WgCABTN1TFXVq5KcSfLu7r6w4enzSQ539y1J3p/k/s3O0d33dvdydy8vLS1d5sgAAItjqpiqqgNZC6kPdffHNj7f3Re6++Jk+8EkB6rq4EwnBQBYQNN8m6+S/GqSx7v7l7Y45trJcamqI5PzPjfLQQEAFtE03+a7Nck/TfJHVfXoZN/PJ7khSbp7JcltSe6sqktJXkhyort79uMCACyWbWOqu/8gSW1zzKkkp2Y1FADAbuEO6AAAA8QUAMAAMQUAMEBMAQAMmObbfLvOodNn5j0C7Cor8x6ALfizDHYDV6YAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABiwf94D7ISn3/n2eY/AJu45fN+8R2ALdz11+7xHAJiJQ6fPXPHXdGUKAGCAmAIAGCCmAAAGiCkAgAFiCgBgwLYxVVUfqKpnq+rzWzx/rKqer6pHJz93z35MAIDFNM2tEX49yakk//kljnmou4/PZCIAgF1k2ytT3f3pJH92BWYBANh1ZvWZqaNV9VhVna2qm2d0TgCAhTeLO6CfT3K4uy9W1VuS3J/kps0OrKqTSU4myQ033DCDlwYAmK/hK1PdfaG7L062H0xyoKoObnHsvd293N3LS0tLoy8NADB3wzFVVddWVU22j0zO+dzoeQEAdoNt3+arqg8nOZbkYFU9k+QXkhxIku5eSXJbkjur6lKSF5Kc6O7esYkBABbItjHV3T+5zfOnsnbrBACAq447oAMADBBTAAADxBQAwAAxBQAwQEwBAAyYxR3QF86h02fmPQKbWJn3ALwEv2cALpcrUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBg/7wH2Al3/If/Oe8R2MRdT90+7xEA2OMOnT5zxV/TlSkAgAFiCgBggJgCABggpgAABogpAIABYgoAYMBUMVVVb66qL1fVE1X1nk2eP1ZVz1fVo5Ofu2c/KgDA4tn2PlNVtS/JryT5B0meSfLZqnqgu7+44dCHuvv4DswIALCwprkydSTJE939ZHe/mOQjSd62s2MBAOwO08TUdUmeXvf4mcm+jY5W1WNVdbaqbt7sRFV1sqrOVdW51dXVyxgXAGCxTBNTtcm+3vD4fJLD3X1LkvcnuX+zE3X3vd293N3LS0tLL2tQAIBFNE1MPZPk0LrH1yf52voDuvtCd1+cbD+Y5EBVHZzZlAAAC2qamPpskpuq6nVV9YokJ5I8sP6Aqrq2qmqyfWRy3udmPSwAwKLZ9tt83X2pqv5lkv+aZF+SD3T3F6rqjsnzK0luS3JnVV1K8kKSE9298a1AAIA9Z9uYSv7fW3cPbti3sm77VJJTsx0NAGDxuQM6AMAAMQUAMEBMAQAMEFMAAAOm+gD6brPyc9897xHY1Jl5DwAAM1fzuoNBVa0meeoKvNTBJN+4Aq/Dy2NdFpe1WUzWZTFZl8U167U53N2b/vMtc4upK6WqznX38rzn4NtZl8VlbRaTdVlM1mVxXcm18ZkpAIABYgoAYMDVEFP3znsANmVdFpe1WUzWZTFZl8V1xdZmz39mCgBgJ10NV6YAAHbMno2pqnpzVX25qp6oqvfMe56rVVUdqqrfr6rHq+oLVfWuyf6/VlWfrKr/Pvmvm4PNSVXtq6rPVdXHJ4+tzZxV1Wuq6qNV9aXJ752j1mUxVNW/mfxZ9vmq+nBVfYe1mY+q+kBVPVtVn1+3b8u1qKr3Tprgy1X1j2Y5y56Mqaral+RXkvzjJD+Q5Cer6gfmO9VV61KSn+nuv5nkh5P8i8lavCfJ73b3TUl+d/KY+XhXksfXPbY28/e+JJ/o7tcnuSVr62Nd5qyqrkvyr5Msd/cPJtmX5ESszbz8epI3b9i36VpM/t45keTmya85PWmFmdiTMZXkSJInuvvJ7n4xyUeSvG3OM12Vuvvr3X1+sv3NrP2lcF3W1uODk8M+mOSfzGXAq1xVXZ/krUnuW7fb2sxRVb06yY8k+dUk6e4Xu/vPY10Wxf4k31lV+5O8MsnXYm3mors/neTPNuzeai3eluQj3f0X3f2VJE9krRVmYq/G1HVJnl73+JnJPuaoqm5M8oYkDyf53u7+erIWXEm+Z46jXc1+OcnPJvnWun3WZr6+L8lqkl+bvP16X1VdE+syd939P5L8xyR/nOTrSZ7v7t+JtVkkW63FjnbBXo2p2mSfry3OUVW9Kmv/ON+7u/vCvOchqarjSZ7t7kfmPQvfZn+Sv5XkP3X3G5L8r3jbaCFMPn/ztiSvS/I3klxTVe+Y71RMaUe7YK/G1DNJDq17fH3WLsUyB1V1IGsh9aHu/thk959W1Wsnz782ybPzmu8qdmuSH6uqr2btrfA3VtVvxNrM2zNJnunuhyePP5q1uLIu8/ejSb7S3avd/b+TfCzJ34m1WSRbrcWOdsFejanPJrmpql5XVa/I2ofOHpjzTFelqqqsffbj8e7+pXVPPZDkpybbP5Xkt6/0bFe77n5vd1/f3Tdm7ffI73X3O2Jt5qq7/yTJ01X1/ZNdb0ryxViXRfDHSX64ql45+bPtTVn7HKi1WRxbrcUDSU5U1V+tqtcluSnJH87qRffsTTur6i1Z+zzIviQf6O575jvR1amq/m6Sh5L8Uf7/53J+Pmufm/rNJDdk7Q+oH+/ujR8k5AqpqmNJ/m13H6+qvx5rM1dV9UNZ+1LAK5I8meSns/Z/fq3LnFXVLyb5iax9U/lzSW5P8qpYmyuuqj6c5FiSg0n+NMkvJLk/W6xFVd2V5J9nbe3e3d1nZzbLXo0pAIArYa++zQcAcEWIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABjwfwAGJHum1sJ8mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some random data points\n",
    "n_points = 100\n",
    "X = np.random.randn(n_points, 10)\n",
    "y = np.random.randn(n_points)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cv = KFold(5)\n",
    "plot_cv_indices(cv, X, y, ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with categorical variables\n",
    "\n",
    "As we have seen in the previous section, a numerical variable is a continuous\n",
    "quantity represented by a real or integer number. Those variables can be\n",
    "naturally handled by machine learning algorithms that typically composed of\n",
    "a sequence of arithmetic instructions such as additions and multiplications.\n",
    "\n",
    "By opposition, categorical variables have discrete values typically represented\n",
    "by string labels taken in a finite list of possible choices. For instance, the\n",
    "variable `native-country` in our dataset is a categorical variable because it\n",
    "encodes the data using a finite list of possible countries (along with the `?`\n",
    "marker when this information is missing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " United-States                 43832\n",
       " Mexico                          951\n",
       " ?                               857\n",
       " Philippines                     295\n",
       " Germany                         206\n",
       " Puerto-Rico                     184\n",
       " Canada                          182\n",
       " El-Salvador                     155\n",
       " India                           151\n",
       " Cuba                            138\n",
       " England                         127\n",
       " China                           122\n",
       " South                           115\n",
       " Jamaica                         106\n",
       " Italy                           105\n",
       " Dominican-Republic              103\n",
       " Japan                            92\n",
       " Guatemala                        88\n",
       " Poland                           87\n",
       " Vietnam                          86\n",
       " Columbia                         85\n",
       " Haiti                            75\n",
       " Portugal                         67\n",
       " Taiwan                           65\n",
       " Iran                             59\n",
       " Greece                           49\n",
       " Nicaragua                        49\n",
       " Peru                             46\n",
       " Ecuador                          45\n",
       " France                           38\n",
       " Ireland                          37\n",
       " Hong                             30\n",
       " Thailand                         30\n",
       " Cambodia                         28\n",
       " Trinadad&Tobago                  27\n",
       " Laos                             23\n",
       " Yugoslavia                       23\n",
       " Outlying-US(Guam-USVI-etc)       23\n",
       " Scotland                         21\n",
       " Honduras                         20\n",
       " Hungary                          19\n",
       " Holand-Netherlands                1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this section, we will present different strategies to\n",
    "encode categorical data into numerical data which can be used by a\n",
    "machine-learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education-num', 'marital-status',\n",
       "       'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
       "       'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"capital-gain\"].dtype.kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [c for c in data.columns\n",
    "                       if data[c].dtype.kind not in [\"i\", \"f\"]]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical = data[categorical_columns]\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datasets is composed of 8 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The datasets is composed of {data_categorical.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Encoding ordinal categories\n",
    "\n",
    "The most intuitive strategy is to encode each category with a number.\n",
    "The `OrdinalEncoder` will transform the data in such manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset encoded contains 8 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  1.,  4.,  7.,  3.,  2.,  1., 39.],\n",
       "       [ 4., 11.,  2.,  5.,  0.,  4.,  1., 39.],\n",
       "       [ 2.,  7.,  2., 11.,  0.,  4.,  1., 39.],\n",
       "       [ 4., 15.,  2.,  7.,  0.,  2.,  1., 39.],\n",
       "       [ 0., 15.,  4.,  0.,  3.,  4.,  0., 39.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "\n",
    "print(f\"The dataset encoded contains {data_encoded.shape[1]} features\")\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all categories have been encoded for each feature\n",
    "independently. We can also notice that the number of features before and after\n",
    "the encoding is the same.\n",
    "\n",
    "However, one has to be careful when using this encoding strategy. Using this\n",
    "integer representation can lead the downstream models to make the assumption\n",
    "that the categories are ordered: 0 is smaller than 1 which is smaller than 2,\n",
    "etc.\n",
    "\n",
    "By default, `OrdinalEncoder` uses a lexicographical strategy to map string\n",
    "category labels to integers. This strategy is completely arbitrary and often be\n",
    "meaningless. For instance suppose the dataset has a categorical variable named\n",
    "\"size\" with categories such as \"S\", \"M\", \"L\", \"XL\". We would like the integer\n",
    "representation to respect the meaning of the sizes by mapping them to increasing\n",
    "integers such as 0, 1, 2, 3. However lexicographical strategy used by default\n",
    "would map the labels \"S\", \"M\", \"L\", \"XL\" to 2, 1, 0, 3.\n",
    "\n",
    "The `OrdinalEncoder` class accepts a \"categories\" constructor argument to pass\n",
    "an the correct ordering explicitly.\n",
    "\n",
    "If a categorical variable does not carry any meaningful order information then\n",
    "this encoding might be misleading to downstream statistical models and you might\n",
    "consider using one-hot encoding instead (see below).\n",
    "\n",
    "Note however that the impact a violation of this ordering assumption is really\n",
    "dependent on the downstream models (for instance linear models are much more\n",
    "sensitive than models built from a ensemble of decision trees).\n",
    "\n",
    "### Encoding nominal categories (without assuming any order)\n",
    "\n",
    "`OneHotEncoder` is an alternative encoder that can prevent the dowstream\n",
    "models to make a false assumption about the ordering of categories. For a\n",
    "given feature, it will create as many new columns as there are possible\n",
    "categories. For a given sample, the value of the column corresponding to the\n",
    "category will be set to `1` while all the columns of the other categories will\n",
    "be set to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is composed of 8 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The dataset is composed of {data_categorical.shape[1]} features\")\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset encoded contains 102 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "print(f\"The dataset encoded contains {data_encoded.shape[1]} features\")\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this numpy array in a dataframe with informative column names as provided by the encoder object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>education_ 10th</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0           0.0                     0.0                   0.0   \n",
       "1           0.0                     0.0                   0.0   \n",
       "2           0.0                     0.0                   1.0   \n",
       "3           0.0                     0.0                   0.0   \n",
       "4           1.0                     0.0                   0.0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                      0.0                 1.0                      0.0   \n",
       "1                      0.0                 1.0                      0.0   \n",
       "2                      0.0                 0.0                      0.0   \n",
       "3                      0.0                 1.0                      0.0   \n",
       "4                      0.0                 0.0                      0.0   \n",
       "\n",
       "   workclass_ Self-emp-not-inc  workclass_ State-gov  workclass_ Without-pay  \\\n",
       "0                          0.0                   0.0                     0.0   \n",
       "1                          0.0                   0.0                     0.0   \n",
       "2                          0.0                   0.0                     0.0   \n",
       "3                          0.0                   0.0                     0.0   \n",
       "4                          0.0                   0.0                     0.0   \n",
       "\n",
       "   education_ 10th  ...  native-country_ Portugal  \\\n",
       "0              0.0  ...                       0.0   \n",
       "1              0.0  ...                       0.0   \n",
       "2              0.0  ...                       0.0   \n",
       "3              0.0  ...                       0.0   \n",
       "4              0.0  ...                       0.0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    0.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     0.0                       0.0   \n",
       "4                    0.0                     0.0                       0.0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                              0.0                            1.0   \n",
       "1                              0.0                            1.0   \n",
       "2                              0.0                            1.0   \n",
       "3                              0.0                            1.0   \n",
       "4                              0.0                            1.0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                      0.0                         0.0  \n",
       "1                      0.0                         0.0  \n",
       "2                      0.0                         0.0  \n",
       "3                      0.0                         0.0  \n",
       "4                      0.0                         0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_encoded = encoder.get_feature_names(data_categorical.columns)\n",
    "pd.DataFrame(data_encoded, columns=columns_encoded).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how the workclass variable of the first 3 records has been encoded and compare this to the original string representation.\n",
    "\n",
    "The number of features after the encoding is than 10 times larger than in the\n",
    "original data because some variables such as `occupation` and `native-country`\n",
    "have many possible categories.\n",
    "\n",
    "We can now integrate this encoder inside a machine learning pipeline as in the\n",
    "case with numerical data: let's train a linear classifier on\n",
    "the encoded data and check the performance of this machine learning pipeline\n",
    "using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different scores obtained are: \n",
      "[0.83222438 0.83560242 0.82872645 0.83312858 0.83466421]\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "scores = cross_val_score(model, data_categorical, target)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.833 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy is: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this representation of the categorical variables of the data is slightly more predictive of the revenue than the numerical variables that we used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 2:\n",
    "\n",
    "- Try to fit a logistic regression model on categorical data transformed by\n",
    "  the OrdinalEncoder instead. What do you observe?\n",
    "\n",
    "Use the dedicated notebook to do this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Using numerical and categorical variables together\n",
    "\n",
    "In the previous sections, we saw that we need to treat data specifically\n",
    "depending of their nature (i.e. numerical or categorical).\n",
    "\n",
    "Scikit-learn provides a `ColumnTransformer` class which will dispatch some\n",
    "specific columns to a specific transformer making it easy to fit a single\n",
    "predictive model on a dataset that combines both kinds of variables together\n",
    "(heterogeneously typed tabular data).\n",
    "\n",
    "We can first define the columns depending on their data type:\n",
    "* **binary encoding** will be applied to categorical columns with only too\n",
    "  possible values (e.g. sex=male or sex=female in this example). Each binary\n",
    "  categorical columns will be mapped to one numerical columns with 0 or 1\n",
    "  values.\n",
    "* **one-hot encoding** will be applied to categorical columns with more that\n",
    "  two possible categories. This encoding will create one additional column for\n",
    "  each possible categorical value.\n",
    "* **numerical scaling** numerical features which will be standardized.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoding_columns = ['sex']\n",
    "one_hot_encoding_columns = ['workclass', 'education', 'marital-status',\n",
    "                            'occupation', 'relationship',\n",
    "                            'race', 'native-country']\n",
    "scaling_columns = ['age', 'education-num', 'hours-per-week',\n",
    "                   'capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our `ColumnTransfomer` by specifying a list of triplet\n",
    "(preprocessor name, transformer, columns). Finally, we can define a pipeline\n",
    "to stack this \"preprocessor\" with our classifier (logistic regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('binary-encoder', OrdinalEncoder(), binary_encoding_columns),\n",
    "    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'),\n",
    "     one_hot_encoding_columns),\n",
    "    ('standard-scaler', StandardScaler(), scaling_columns)\n",
    "])\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is more complex than the previous models but still follows the\n",
    "same API:\n",
    "- the `fit` method is called to preprocess the data then train the classifier;\n",
    "- the `predict` method can make predictions on new data;\n",
    "- the `score` method is used to predict on the test data and compare the\n",
    "  predictions to the expected test labels to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=42\n",
    ")\n",
    "model.fit(data_train, target_train)\n",
    "model.predict(data_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>56</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23881</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30507</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14344</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28911</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19484</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass   education  education-num       marital-status  \\\n",
       "7762    56   Private     HS-grad              9             Divorced   \n",
       "23881   25   Private     HS-grad              9   Married-civ-spouse   \n",
       "30507   43   Private   Bachelors             13             Divorced   \n",
       "28911   32   Private     HS-grad              9   Married-civ-spouse   \n",
       "19484   39   Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "              occupation    relationship    race      sex  capital-gain  \\\n",
       "7762       Other-service       Unmarried   White   Female             0   \n",
       "23881   Transport-moving       Own-child   Other     Male             0   \n",
       "30507     Prof-specialty   Not-in-family   White   Female         14344   \n",
       "28911   Transport-moving         Husband   White     Male             0   \n",
       "19484              Sales            Wife   White   Female             0   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  \n",
       "7762              0              40   United-States  \n",
       "23881             0              40   United-States  \n",
       "30507             0              40   United-States  \n",
       "28911             0              40   United-States  \n",
       "19484             0              30   United-States  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579968880517567"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can also be cross-validated as usual (instead of using a single\n",
    "train-test split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different scores obtained are: \n",
      "[0.85105947 0.8498311  0.84756347 0.85268223 0.85513923]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, data, target, cv=5)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.851 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy is: {scores.mean():.3f} +- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compound model has a higher predictive accuracy than the\n",
    "two models that used numerical and categorical variables in\n",
    "isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a more powerful model\n",
    "\n",
    "Linear models are very nice because they are usually very cheap to train,\n",
    "small to deploy, fast to predict and give a good baseline.\n",
    "\n",
    "However it is often useful to check whether more complex models such as\n",
    "ensemble of decision trees can lead to higher predictive performance.\n",
    "\n",
    "In the following we try a scalable implementation of the Gradient Boosting\n",
    "Machine algorithm. For this class of models, we know that contrary to linear\n",
    "models, it is useless to scale the numerical features and furthermore it is\n",
    "both safe and significantly more computationally efficient use an arbitrary\n",
    "integer encoding for the categorical variable even if the ordering is\n",
    "arbitrary. Therefore we adapt the preprocessing pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'categorical_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HistGradientBoostingClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# For each categorical column, extract the list of all possible categories\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# in some arbritrary order.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m categories \u001b[38;5;241m=\u001b[39m [data[column]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m data[\u001b[43mcategorical_columns\u001b[49m]]\n\u001b[0;32m      8\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n\u001b[0;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m, OrdinalEncoder(categories\u001b[38;5;241m=\u001b[39mcategories), categorical_columns),\n\u001b[0;32m     10\u001b[0m ], remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m make_pipeline(preprocessor, HistGradientBoostingClassifier())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categorical_columns' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# For each categorical column, extract the list of all possible categories\n",
    "# in some arbritrary order.\n",
    "categories = [data[column].unique() for column in data[categorical_columns]]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', OrdinalEncoder(categories=categories), categorical_columns),\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "model = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n",
    "model.fit(data_train, target_train)\n",
    "print(model.score(data_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We can observe that we get significantly higher accuracies with the Gradient\n",
    "Boosting model. This is often what we observe whenever the dataset has a large\n",
    "number of samples and limited number of informative features (e.g. less than\n",
    "1000) with a mix of numerical and categorical variables.\n",
    "\n",
    "This explains why Gradient Boosted Machines are very popular among datascience\n",
    "practitioners who work with tabular data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "- Check that scaling the numerical features does not impact the speed or\n",
    "  accuracy of HistGradientBoostingClassifier\n",
    "- Check that one-hot encoding the categorical variable does not improve the\n",
    "  accuracy of HistGradientBoostingClassifier but slows down the training.\n",
    "\n",
    "Use the dedicated notebook to do this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "notebooks//ipynb,python_scripts//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
